{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10568570,"sourceType":"datasetVersion","datasetId":6539786}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nimport os\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndata_dir = '/kaggle/input/dataset-2/data'\nimage_size = 128\ndata_transform = transforms.Compose([\n    transforms.Resize([image_size, image_size]),\n    transforms.Grayscale(num_output_channels=1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])\n\nfull_dataset = datasets.ImageFolder(root=data_dir, transform=data_transform)\n\ntrain_size = int(0.8* len(full_dataset))\nval_size = (len(full_dataset) - train_size)//2\ntest_size = len(full_dataset) - train_size -  val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader  = DataLoader(val_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n\n\nclass Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, padding=1, kernel_size=3),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n            nn.MaxPool2d(kernel_size=2),\n            \n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        \n        self.dense_layers = nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(0.3),\n            nn.Linear(128 * 16 * 16, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.3),\n            nn.Linear(256, 100)\n        )\n    \n    def forward(self,x):\n        x =self.features(x)\n        x = self.dense_layers(x)\n        return x\n    \nmodel = Classifier().to(device)\n\nloss_func = nn.CrossEntropyLoss()\noptimiser = optim.Adam(model.parameters(), lr=0.0003)\n\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0\n    correct = 0\n    total = 0\n    \n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        loss = loss_func(outputs, labels)\n        \n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n        \n        running_loss += loss.item()\n        max_val, prediction = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (prediction==labels).sum().item()\n        \n    train_loss = running_loss/len(train_loader)\n    train_accuracy = (correct/total)*100\n    \n    \n    model.eval()\n    val_loss = 0\n    correct = 0\n    total = 0\n    \n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        loss = loss_func(outputs, labels)\n        \n        val_loss += loss.item()\n        max_val, prediction = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (prediction == labels).sum().item()\n        \n    val_loss = val_loss / len(val_loader)\n    val_acc = 100 * correct / total\n        \n    print(f'Epoch [{epoch+1}/{num_epochs}]')\n    print(f'Train Loss: {train_loss:.4f}, Acc: {train_accuracy:.2f}%')\n    print(f'Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:08:06.452241Z","iopub.execute_input":"2025-01-25T14:08:06.452531Z","iopub.status.idle":"2025-01-25T14:14:40.747500Z","shell.execute_reply.started":"2025-01-25T14:08:06.452509Z","shell.execute_reply":"2025-01-25T14:14:40.746820Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10]\nTrain Loss: 3.9654, Acc: 14.12%\nVal Loss: 2.9690, Acc: 49.55%\nEpoch [2/10]\nTrain Loss: 2.0191, Acc: 69.36%\nVal Loss: 1.1649, Acc: 86.45%\nEpoch [3/10]\nTrain Loss: 0.7680, Acc: 93.00%\nVal Loss: 0.5652, Acc: 95.55%\nEpoch [4/10]\nTrain Loss: 0.2573, Acc: 98.93%\nVal Loss: 0.3016, Acc: 97.91%\nEpoch [5/10]\nTrain Loss: 0.0941, Acc: 99.84%\nVal Loss: 0.2474, Acc: 98.55%\nEpoch [6/10]\nTrain Loss: 0.0445, Acc: 99.99%\nVal Loss: 0.3103, Acc: 98.36%\nEpoch [7/10]\nTrain Loss: 0.0250, Acc: 100.00%\nVal Loss: 0.2119, Acc: 98.91%\nEpoch [8/10]\nTrain Loss: 0.0169, Acc: 100.00%\nVal Loss: 0.2165, Acc: 98.82%\nEpoch [9/10]\nTrain Loss: 0.0117, Acc: 100.00%\nVal Loss: 0.1618, Acc: 98.91%\nEpoch [10/10]\nTrain Loss: 0.0086, Acc: 100.00%\nVal Loss: 0.1558, Acc: 99.00%\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"model.eval()\ntest_loss = 0\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        loss = loss_func(outputs, labels)\n        \n        test_loss += loss.item()\n        max_val, prediction = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (prediction == labels).sum().item()\n        \ntest_loss = test_loss / len(test_loader)\ntest_acc = 100 * correct / total\n\nprint(f'\\nTest Results:')\nprint(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T14:16:36.897088Z","iopub.execute_input":"2025-01-25T14:16:36.897376Z","iopub.status.idle":"2025-01-25T14:16:43.751010Z","shell.execute_reply.started":"2025-01-25T14:16:36.897355Z","shell.execute_reply":"2025-01-25T14:16:43.750220Z"}},"outputs":[{"name":"stdout","text":"\nTest Results:\nTest Loss: 0.1268, Test Accuracy: 98.82%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}